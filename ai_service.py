"""
AI æœå‹™æ¨¡çµ„ - Campus Help (æœ€çµ‚ç©©å®šç‰ˆ)
ä¿®æ­£ï¼š
1. ä½¿ç”¨ç©©å®šæ¨¡å‹ gemini-2.0-flash
2. é™ä½ AI æº«åº¦é¿å…éåº¦å„ªåŒ–
3. åŠ å¼· Prompt ç´„æŸåŠ›
"""
import os
from dotenv import load_dotenv

load_dotenv()

# ğŸ”§ Demo æ¨¡å¼é–‹é—œ
DEMO_MODE = False  # False é—œé–‰ Demo æ¨¡å¼

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: google-generativeai æœªå®‰è£ï¼ŒAI åŠŸèƒ½å°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")


class AIService:
    """AI æœå‹™é¡åˆ¥"""
    
    # æ•æ„Ÿé—œéµå­—æ¸…å–®
    DANGER_KEYWORDS = {
        'critical': [
            'ä»£è€ƒ', 'ä»£å¯«', 'ä»£å¯«å ±å‘Š', 'ä»£å¯«ä½œæ¥­', 'å¹«å¯«å ±å‘Š',
            'ä»£è³¼è¸', 'ä»£è³¼é…’', 'ä»£è²·è¸', 'ä»£è²·é…’', 'è²·è¸', 'è²·é…’',
            'å€ŸéŒ¢', 'è²¸æ¬¾', 'æ”¾è²¸', 'é«˜åˆ©è²¸', 'å€Ÿæ¬¾', 'æ€¥éœ€ç”¨éŒ¢',
            'è‰²æƒ…', 'æ´äº¤', 'ç´„ç‚®', 'ä¸€å¤œæƒ…', 'é™ªç¡',
            'æ¯’å“', 'å¤§éº»', 'æ–é ­ä¸¸', 'Kä»–å‘½',
            'è³­åš', 'ç·šä¸Šè³­å ´', 'ç°½è³­', 'å…­åˆå½©'
        ],
        'high': [
            'å¹«å¯«', 'å¹«åšä½œæ¥­', 'æœŸæœ«å ±å‘Š', 'æœŸä¸­è€ƒ', 'è€ƒè©¦ç­”æ¡ˆ',
            'æˆäºº', '18ç¦', 'è£¸éœ²', 'æ€§æ„Ÿ',
            'ç¾é‡‘äº¤æ˜“', 'å¤§é‡ç¾é‡‘', 'åŒ¯æ¬¾', 'è½‰å¸³',
            'éæ³•', 'é•æ³•', 'çŠ¯ç½ª', 'è©é¨™'
        ],
        'medium': [
            'ä»£è²·', 'ä»£è³¼', 'ä»£é ˜', 'å¹«è²·æ±è¥¿',
            'æ·±å¤œ', 'åŠå¤œ', 'å‡Œæ™¨',
            'é™ªä¼´', 'é™ªèŠ', 'é™ªåƒé£¯',
            'ç§äººä½è™•', 'å®¶è£¡', 'å®¿èˆæˆ¿é–“'
        ]
    }
    
    def __init__(self):
        """åˆå§‹åŒ– AI æœå‹™"""
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        
        if DEMO_MODE:
            print("âš ï¸ AI Demo æ¨¡å¼å·²å•Ÿç”¨ï¼ˆä¸å‘¼å«çœŸå¯¦ APIï¼‰")
            return
        
        if GEMINI_AVAILABLE and self.api_key:
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel(
                    'gemini-2.0-flash',
                    generation_config={'temperature': 0.5}
                )
                print("âœ… Gemini AI å·²å•Ÿç”¨ (gemini-2.0-flash, temperature=0.3)")
            except Exception as e:
                print(f"âš ï¸  Gemini åˆå§‹åŒ–å¤±æ•—: {e}")
                self.model = None
        else:
            print("âš ï¸  Gemini API Key æœªè¨­å®šï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
    
    @staticmethod
    def optimize_task_description(description):
        """å„ªåŒ–ä»»å‹™æè¿°ï¼ˆä¿å®ˆç‰ˆï¼Œé¿å…éåº¦è…¦è£œï¼‰"""
        if DEMO_MODE:
            return {
                'success': True,
                'optimized_description': f"{description}\n\nâœ¨ **AI å„ªåŒ–å»ºè­°ï¼ˆDemo æ¨¡å¼ï¼‰**ï¼š\nâ€¢ å»ºè­°åŠ ä¸Šå…·é«”æ™‚é–“éœ€æ±‚ï¼ˆä¾‹ï¼šé€±ä¸‰ä¸‹åˆ2é»ï¼‰\nâ€¢ å»ºè­°èªªæ˜ä»»å‹™é›£åº¦èˆ‡æ‰€éœ€æŠ€èƒ½\nâ€¢ å»ºè­°æä¾›è¯çµ¡æ–¹å¼æˆ–é›†åˆåœ°é»"
            }
        
        service = AIService()
        
        if not service.model:
            return {
                'success': True,
                'optimized_description': f"{description}\n\nğŸ’¡ [AI å»ºè­°] å¯ä»¥è£œå……ä»»å‹™çš„å…·é«”è¦æ±‚ã€æ³¨æ„äº‹é …æˆ–æœŸæœ›æˆæœï¼Œè®“å¹«åŠ©è€…æ›´å®¹æ˜“ç†è§£ã€‚"
            }
        
        try:
            # ğŸ”§ ä¿®æ”¹ï¼šåŠ å¼· Prompt ç´„æŸï¼Œé¿å…éåº¦å„ªåŒ–
            prompt = f"""
ä½ æ˜¯ä¸€å€‹ä»»å‹™æè¿°å„ªåŒ–åŠ©æ‰‹ã€‚è«‹**è¬¹æ…å„ªåŒ–**ä»¥ä¸‹ä»»å‹™æè¿°ï¼Œä¿æŒåŸæ„ä¸¦è£œå……å¿…è¦è³‡è¨Šã€‚

ã€åŸå§‹æè¿°ã€‘
{description}

ã€å„ªåŒ–è¦å‰‡ã€‘
1. âœ… **ä¿æŒåŸæ„**ï¼šä¸è¦æ”¹è®Šä»»å‹™æœ¬è³ªå’Œå…§å®¹
2. âœ… **è£œå……ç´°ç¯€**ï¼šå¯ä»¥é©åº¦è£œå……ä»»å‹™çš„å…·é«”è¦æ±‚ã€æ³¨æ„äº‹é …æˆ–æœŸæœ›æˆæœ
3. âœ… **ç°¡æ½”è¡¨é”**ï¼šå„ªåŒ–å¾Œçš„é•·åº¦ä¸è¶…éåŸæ–‡çš„ 1.3 å€
4. âŒ **ç¦æ­¢è…¦è£œ**ï¼šä¸è¦ç·¨é€ æ—¥æœŸã€åœ°å€ã€é‡‘é¡ã€é£²æ–™å£å‘³ç­‰å…·é«”ç´°ç¯€
5. âŒ **ç¦æ­¢èª‡é£¾**ï¼šä¸è¦åŠ å…¥ã€Œæ€¥éœ€ã€ã€Œå‹•ä½œå¿«ã€ã€Œæº–æ™‚ã€ç­‰èª‡å¼µç”¨è©
6. âŒ **ç¦æ­¢æåŠ**ï¼šä¸è¦æã€Œæ™‚é–“ã€ã€Œåœ°é»ã€ã€Œå ±é…¬ã€ã€Œé»æ•¸ã€ï¼ˆé€™äº›å·²åœ¨è¡¨å–®å…¶ä»–æ¬„ä½å¡«å¯«ï¼‰

ã€è¼¸å‡ºæ ¼å¼ã€‘
ç›´æ¥è¼¸å‡ºå„ªåŒ–å¾Œçš„æè¿°ï¼Œä¸è¦åŠ å‰ç¶´æˆ–èªªæ˜ã€‚å¦‚æœåŸæè¿°å·²ç¶“å¾ˆæ¸…æ¥šï¼Œå¯ä»¥åªåšå¾®èª¿ã€‚

ã€ç¯„ä¾‹ã€‘
è¼¸å…¥ï¼šé€±ä¸‰ä¸‹åˆå¹«æˆ‘è²·ä¾¿ç•¶è²·é£²æ–™
è¼¸å‡ºï¼šå¹«å¿™è³¼è²·åˆé¤ä¾¿ç•¶å’Œé£²æ–™ï¼Œå¸Œæœ›èƒ½é †ä¾¿å¹«å¿™ç¢ºèªåº—å®¶ç‡Ÿæ¥­æ™‚é–“

ç¾åœ¨è«‹å„ªåŒ–ä¸Šé¢çš„ä»»å‹™æè¿°ï¼š
"""
            
            response = service.model.generate_content(prompt)
            optimized = response.text.strip()
            
            '''
            # ğŸ”§ é˜²å‘†æ©Ÿåˆ¶ï¼šå¦‚æœå„ªåŒ–çµæœå¤ªé•·ï¼ˆè¶…é 2 å€ï¼‰ï¼Œæ‰è¿”å›å»ºè­°
            if len(optimized) > len(description) * 2.0:
                return {
                    'success': True,
                    'optimized_description': f"{description}\n\nğŸ’¡ **AI å»ºè­°**ï¼šå¯ä»¥è£œå……å…·é«”æ™‚é–“ã€åœ°é»å’Œé ç®—ï¼Œè®“å¹«åŠ©è€…æ›´å®¹æ˜“è©•ä¼°ã€‚"
                }
            '''
            
            return {
                'success': True,
                'optimized_description': optimized
            }
        
        except Exception as e:
            print(f"AI å„ªåŒ–å¤±æ•—: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    @staticmethod
    def risk_assessment(description, category):
        """ä»»å‹™é¢¨éšªå¯©æŸ¥"""
        service = AIService()
        
        # é—œéµå­—æª¢æ¸¬ï¼ˆä¸è®Šï¼‰
        critical_flags = []
        high_flags = []
        medium_flags = []
        
        desc_lower = description.lower()
        
        for keyword in service.DANGER_KEYWORDS['critical']:
            if keyword in desc_lower:
                critical_flags.append(keyword)
        
        for keyword in service.DANGER_KEYWORDS['high']:
            if keyword in desc_lower:
                high_flags.append(keyword)
        
        for keyword in service.DANGER_KEYWORDS['medium']:
            if keyword in desc_lower:
                medium_flags.append(keyword)
        
        if critical_flags:
            return {
                'success': True,
                'data': {
                    'risk_level': 'critical',
                    'risk_score': 1.0,
                    'recommendation': 'è‡ªå‹•æ‹’çµ•',
                    'reason': f'åµæ¸¬åˆ°åš´é‡é•è¦å…§å®¹ï¼š{", ".join(critical_flags[:3])}',
                    'flags': critical_flags,
                    'can_appeal': False,
                    'warning': 'âš ï¸ åš´é‡é•è¦ï¼šæ­¤ä»»å‹™æ¶‰åŠé•åæ ¡è¦æˆ–æ³•å¾‹ï¼Œå·²è¢«ç³»çµ±è‡ªå‹•æ‹’çµ•ã€‚'
                }
            }
        
        if high_flags:
            return {
                'success': True,
                'data': {
                    'risk_level': 'high',
                    'risk_score': 0.8,
                    'recommendation': 'éœ€äººå·¥å¯©æ ¸',
                    'reason': f'åµæ¸¬åˆ°é«˜é¢¨éšªå…§å®¹ï¼š{", ".join(high_flags[:3])}',
                    'flags': high_flags,
                    'can_appeal': True,
                    'warning': 'âš ï¸ é«˜é¢¨éšªï¼šä»»å‹™å·²é€äº¤äººå·¥å¯©æ ¸ï¼Œå¦‚æœ‰èª¤åˆ¤å¯é»æ“Šã€Œç”³è¨´ã€æŒ‰éˆ•ã€‚'
                }
            }
        
        if medium_flags:
            return {
                'success': True,
                'data': {
                    'risk_level': 'medium',
                    'risk_score': 0.5,
                    'recommendation': 'è­¦å‘Šä½†å…è¨±',
                    'reason': f'åµæ¸¬åˆ°éœ€æ³¨æ„äº‹é …ï¼š{", ".join(medium_flags[:3])}',
                    'flags': medium_flags,
                    'can_appeal': True,
                    'warning': 'âš ï¸ æº«é¦¨æé†’ï¼šè«‹ç¢ºä¿ä»»å‹™å…§å®¹åˆæ³•ä¸”å®‰å…¨ï¼Œé¿å…ç§ä¸‹é‡‘éŒ¢äº¤æ˜“æˆ–æ·±å¤œè¦‹é¢ã€‚'
                }
            }
        
        if DEMO_MODE or not service.model:
            return {
                'success': True,
                'data': {
                    'risk_level': 'safe',
                    'risk_score': 0.1,
                    'recommendation': 'è‡ªå‹•é€šé',
                    'reason': 'æœªç™¼ç¾æ˜é¡¯é¢¨éšª',
                    'flags': [],
                    'can_appeal': False,
                    'warning': None
                }
            }
        
        # AI èªæ„åˆ†æï¼ˆä¸è®Šï¼‰
        try:
            prompt = f"""
ä½ æ˜¯ä¸€å€‹å…§å®¹å®‰å…¨å¯©æŸ¥å°ˆå®¶ã€‚è«‹è©•ä¼°ä»¥ä¸‹ä»»å‹™æ˜¯å¦é•åå¹³å°è¦ç¯„ã€‚

ä»»å‹™åˆ†é¡ï¼š{category}
ä»»å‹™æè¿°ï¼š
{description}

å¹³å°ç¦æ­¢äº‹é …ï¼š
1. ä»£è€ƒã€ä»£å¯«å ±å‘Šï¼ˆé•åå­¸è¡“èª ä¿¡ï¼‰
2. ä»£è³¼è¸é…’ã€æˆäººå…§å®¹ï¼ˆæ³•å¾‹é™åˆ¶ï¼‰
3. é‡‘éŒ¢å€Ÿè²¸ç›¸é—œï¼ˆè¶…å‡ºæœå‹™ç¯„åœï¼‰
4. å±éšªæˆ–é•è¦æ´»å‹•ï¼ˆå®‰å…¨è€ƒé‡ï¼‰
5. æ·±å¤œç§äººå ´æ‰€è¦‹é¢ï¼ˆå®‰å…¨é¢¨éšªï¼‰

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "risk_level": "safe/low/medium/high/critical",
  "risk_score": 0.0-1.0,
  "recommendation": "è‡ªå‹•é€šé/è­¦å‘Šä½†å…è¨±/éœ€äººå·¥å¯©æ ¸/è‡ªå‹•æ‹’çµ•",
  "reason": "ç°¡çŸ­èªªæ˜",
  "flags": ["é¢¨éšªæ¨™è¨˜åˆ—è¡¨"],
  "hidden_risk": "æ˜¯å¦æœ‰éš±è—çš„é•è¦æš—ç¤º"
}}

åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
            
            response = service.model.generate_content(prompt)
            result_text = response.text.strip()
            
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            import json
            data = json.loads(result_text)
            data['can_appeal'] = data['risk_level'] in ['medium', 'high']
            
            return {
                'success': True,
                'data': data
            }
        
        except Exception as e:
            print(f"AI é¢¨éšªå¯©æŸ¥å¤±æ•—: {e}")
            return {
                'success': True,
                'data': {
                    'risk_level': 'safe',
                    'risk_score': 0.2,
                    'recommendation': 'è‡ªå‹•é€šé',
                    'reason': 'AI å¯©æŸ¥æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå·²é€šéé—œéµå­—æª¢æ¸¬',
                    'flags': [],
                    'can_appeal': False
                }
            }
    
    @staticmethod
    def parse_task_description(description):
        """è§£æä»»å‹™æè¿°ï¼ˆä¿ç•™ï¼Œä½†å¯é¸ç”¨ï¼‰"""
        if DEMO_MODE:
            return {
                'success': True,
                'data': {
                    'required_skills': ['é€šç”¨æŠ€èƒ½'],
                    'estimated_time': 'æœªæŒ‡å®š',
                    'location_type': 'å¯¦é«”',
                    'urgency': 'normal'
                }
            }
        
        service = AIService()
        
        if not service.model:
            return {
                'success': True,
                'data': {
                    'required_skills': ['é€šç”¨æŠ€èƒ½'],
                    'estimated_time': 'æœªæŒ‡å®š',
                    'location_type': 'å¯¦é«”',
                    'urgency': 'normal'
                }
            }
        
        try:
            prompt = f"""
è«‹åˆ†æä»¥ä¸‹ä»»å‹™æè¿°ï¼Œæå–é—œéµè³‡è¨Šã€‚

ä»»å‹™æè¿°ï¼š
{description}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "required_skills": ["æ‰€éœ€æŠ€èƒ½åˆ—è¡¨"],
  "estimated_time": "é ä¼°æ™‚é•·",
  "location_type": "å¯¦é«”/ç·šä¸Š/æ··åˆ",
  "urgency": "low/normal/high",
  "key_points": ["é—œéµè¦é»åˆ—è¡¨"]
}}

åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
            
            response = service.model.generate_content(prompt)
            result_text = response.text.strip()
            
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            import json
            data = json.loads(result_text)
            
            return {
                'success': True,
                'data': data
            }
        
        except Exception as e:
            print(f"AI è§£æå¤±æ•—: {e}")
            return {
                'success': False,
                'error': str(e)
            }


if __name__ == '__main__':
    print("æ¸¬è©¦ AI æœå‹™...")
    
    # æ¸¬è©¦ 1: å®‰å…¨ä»»å‹™
    print("\n1. æ¸¬è©¦å®‰å…¨ä»»å‹™:")
    result = AIService.risk_assessment("å¹«å¿™æ¬å®¿èˆè¡Œæï¼Œç´„20åˆ†é˜", "æ—¥å¸¸æ”¯æ´")
    print(f"   é¢¨éšªç­‰ç´š: {result['data']['risk_level']}")
    print(f"   å»ºè­°: {result['data']['recommendation']}")
    
    # æ¸¬è©¦ 2: åš´é‡é•è¦
    print("\n2. æ¸¬è©¦åš´é‡é•è¦:")
    result = AIService.risk_assessment("å¹«æˆ‘ä»£è€ƒæœŸæœ«è€ƒ", "å­¸ç¿’äº’åŠ©")
    print(f"   é¢¨éšªç­‰ç´š: {result['data']['risk_level']}")
    print(f"   å»ºè­°: {result['data']['recommendation']}")
    print(f"   å¯ç”³è¨´: {result['data']['can_appeal']}")
    
    # æ¸¬è©¦ 3: AI å„ªåŒ–æè¿°
    print("\n3. æ¸¬è©¦ AI å„ªåŒ–:")
    result = AIService.optimize_task_description("é€±ä¸‰ä¸‹åˆå¹«æˆ‘è²·ä¾¿ç•¶è²·é£²æ–™")
    if result['success']:
        print(f"   å„ªåŒ–çµæœ: {result['optimized_description']}")